{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c3eb4d-d9a1-47c5-b881-c380c2e7d3cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 셀 1: 사용자 인터페이스 (UI) 설정\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Google Colab의 display와 ipywidgets의 display가 충돌할 수 있으므로, 명시적으로 스타일을 지정합니다.\n",
    "display(HTML(\"<style>.widget-label { min-width: 25ex !important; }</style>\"))\n",
    "\n",
    "class UI:\n",
    "    def __init__(self):\n",
    "        # --- 모델 설정 ---\n",
    "        self.model_quant = widgets.Dropdown(options=[\"Q4_K_M\", \"Q5_K_M\", \"Q6_K\", \"Q8_0\"], value=\"Q4_K_M\", description=\"Model Quantization:\")\n",
    "        self.lightx2v_rank = widgets.Dropdown(options=[\"32\", \"64\", \"128\"], value=\"32\", description=\"Lightx2v Rank:\")\n",
    "\n",
    "        # --- LoRA 다운로드 설정 ---\n",
    "        self.download_lora_1 = widgets.Checkbox(value=False, description=\"Download LoRA 1\")\n",
    "        self.lora_1_url = widgets.Text(value=\"Put your LoRA URL here\", description=\"LoRA 1 URL:\")\n",
    "        self.download_lora_2 = widgets.Checkbox(value=False, description=\"Download LoRA 2\")\n",
    "        self.lora_2_url = widgets.Text(value=\"Put your LoRA URL here\", description=\"LoRA 2 URL:\")\n",
    "        self.download_lora_3 = widgets.Checkbox(value=False, description=\"Download LoRA 3\")\n",
    "        self.lora_3_url = widgets.Text(value=\"https://huggingface.co/Remade-AI/Rotate/resolve/main/rotate_20_epochs.safetensors\", description=\"LoRA 3 URL:\")\n",
    "        self.civitai_token = widgets.Password(description=\"Civitai Token:\", value=\"\")\n",
    "\n",
    "        # --- 비디오 생성 설정 ---\n",
    "        self.positive_prompt = widgets.Textarea(value=\"slow jumping and fast dancing\", description=\"Positive Prompt:\", layout={'width': '95%', 'height': '80px'})\n",
    "        self.prompt_assist = widgets.Dropdown(options=[\"none\", \"walking to camera\", \"walking from camera\", \"swaying\"], value=\"none\", description=\"Prompt Assist:\")\n",
    "        self.negative_prompt = widgets.Textarea(value=\"色调艳丽，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走\", description=\"Negative Prompt:\", layout={'width': '95%', 'height': '80px'})\n",
    "        self.width = widgets.IntText(value=480, description=\"Width:\")\n",
    "        self.height = widgets.IntText(value=720, description=\"Height:\")\n",
    "        self.seed = widgets.IntText(value=0, description=\"Seed (0=random):\")\n",
    "        self.high_noise_steps = widgets.IntSlider(value=3, min=1, max=25, step=1, description=\"High Noise Steps:\")\n",
    "        self.steps = widgets.IntSlider(value=6, min=1, max=50, step=1, description=\"Total Steps:\")\n",
    "        self.cfg_scale = widgets.FloatSlider(value=1.0, min=1.0, max=20.0, step=0.1, description=\"CFG Scale:\")\n",
    "        self.sampler_name = widgets.Dropdown(options=[\"uni_pc\", \"uni_pc_bh2\", \"ddim\",\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\",\"dpm_2\", \"dpm_2_ancestral\",\"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\",\"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\",\"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\",\"gradient_estimation\", \"er_sde\", \"seeds_2\", \"seeds_3\"], value=\"euler\", description=\"Sampler:\")\n",
    "        self.scheduler = widgets.Dropdown(options=[\"simple\",\"normal\",\"karras\",\"exponential\",\"sgm_uniform\",\"ddim_uniform\",\"beta\",\"linear_quadratic\",\"kl_optimal\"], value=\"simple\", description=\"Scheduler:\")\n",
    "        self.frames = widgets.IntSlider(value=81, min=1, max=120, step=1, description=\"Frames:\")\n",
    "        self.overwrite_previous_video = widgets.Checkbox(value=True, description=\"Overwrite Previous Video\")\n",
    "\n",
    "        # --- 모델 고급 설정 ---\n",
    "        self.use_sage_attention = widgets.Checkbox(value=True, description=\"Use Sage Attention:\")\n",
    "        self.use_flow_shift = widgets.Checkbox(value=True, description=\"Use Flow Shift:\")\n",
    "        self.flow_shift = widgets.FloatSlider(value=8.0, min=0.0, max=100.0, step=0.01, description=\"Flow Shift 1:\")\n",
    "        self.flow_shift2 = widgets.FloatSlider(value=8.0, min=0.0, max=100.0, step=0.01, description=\"Flow Shift 2:\")\n",
    "\n",
    "        # --- Wan 2.1 LoRA 설정 ---\n",
    "        self.use_lightx2v = widgets.Checkbox(value=True, description=\"Use Lightx2v:\")\n",
    "        self.lightx2v_Strength = widgets.FloatSlider(value=3.0, min=-10.0, max=10.0, step=0.01, description=\"Lightx2v Strength:\")\n",
    "        self.use_lightx2v2 = widgets.Checkbox(value=True, description=\"Use Lightx2v2 (Pusa):\")\n",
    "        self.lightx2v2_Strength = widgets.FloatSlider(value=1.5, min=-10.0, max=10.0, step=0.01, description=\"Lightx2v2 Strength:\")\n",
    "\n",
    "        # --- 커스텀 LoRA 설정 ---\n",
    "        self.use_lora_1 = widgets.Checkbox(value=False, description=\"Use Custom LoRA 1:\")\n",
    "        self.lora_1_strength = widgets.FloatSlider(value=1.0, min=-10.0, max=10.0, step=0.01, description=\"LoRA 1 Strength:\")\n",
    "        self.use_lora_2 = widgets.Checkbox(value=False, description=\"Use Custom LoRA 2:\")\n",
    "        self.lora_2_strength = widgets.FloatSlider(value=1.0, min=-10.0, max=10.0, step=0.01, description=\"LoRA 2 Strength:\")\n",
    "        self.use_lora_3 = widgets.Checkbox(value=False, description=\"Use Custom LoRA 3:\")\n",
    "        self.lora_3_strength = widgets.FloatSlider(value=1.0, min=-10.0, max=10.0, step=0.01, description=\"LoRA 3 Strength:\")\n",
    "\n",
    "        # --- Teacache 설정 ---\n",
    "        self.rel_l1_thresh = widgets.FloatSlider(value=0, min=0.0, max=10.0, step=0.001, description=\"Rel L1 Thresh:\")\n",
    "        self.start_percent = widgets.FloatSlider(value=0.2, min=0.0, max=1.0, step=0.01, description=\"Start Percent:\")\n",
    "        self.end_percent = widgets.FloatSlider(value=1.0, min=0.0, max=1.0, step=0.01, description=\"End Percent:\")\n",
    "        \n",
    "        # --- 프레임 보간 설정 ---\n",
    "        self.interpolate_video = widgets.Checkbox(value=True, description=\"Apply Frame Interpolation\")\n",
    "        self.frame_multiplier = widgets.IntText(value=2, description=\"Frame Multiplier:\")\n",
    "        self.interpolated_fps = widgets.IntText(value=30, description=\"Interpolated FPS:\")\n",
    "        self.crf_value = widgets.IntSlider(value=17, min=0, max=51, step=1, description=\"CRF (Quality):\")\n",
    "        \n",
    "        # --- 업스케일 설정 ---\n",
    "        self.apply_upscaling = widgets.Checkbox(value=True, description=\"Apply Upscaling\")\n",
    "        self.upscale_by = widgets.FloatSlider(value=2.0, min=1.0, max=4.0, step=0.1, description=\"Upscale By:\")\n",
    "        self.upscale_denoise = widgets.FloatSlider(value=0.2, min=0.0, max=1.0, step=0.01, description=\"Denoise:\")\n",
    "        self.upscale_steps = widgets.IntSlider(value=20, min=1, max=100, step=1, description=\"Steps:\")\n",
    "        self.upscale_model_name = widgets.Dropdown(\n",
    "            options=[\"4x-UltraSharp.pth\", \"4x_foolhardy_Remacri.pth\", \"4x-AnimeSharp.pth\"],\n",
    "            value=\"4x-UltraSharp.pth\",\n",
    "            description=\"Upscale Model:\"\n",
    "        )\n",
    "\n",
    "        # --- 파일 업로드 ---\n",
    "        self.image_uploader = widgets.FileUpload(accept='image/*', description='Upload Image')\n",
    "        self.display_upload_check = widgets.Checkbox(value=False, description=\"Display uploaded image\")\n",
    "\n",
    "\n",
    "    def display_ui(self):\n",
    "        lora_downloads = widgets.VBox([\n",
    "            self.download_lora_1, self.lora_1_url,\n",
    "            self.download_lora_2, self.lora_2_url,\n",
    "            self.download_lora_3, self.lora_3_url,\n",
    "            self.civitai_token\n",
    "        ])\n",
    "        \n",
    "        generation_settings = widgets.VBox([\n",
    "            self.positive_prompt, self.prompt_assist, self.negative_prompt,\n",
    "            widgets.HBox([self.width, self.height]),\n",
    "            self.seed, self.high_noise_steps, self.steps, self.cfg_scale,\n",
    "            self.sampler_name, self.scheduler, self.frames, self.overwrite_previous_video\n",
    "        ])\n",
    "        \n",
    "        model_config = widgets.VBox([\n",
    "            self.use_sage_attention,\n",
    "            widgets.HBox([self.use_flow_shift, self.flow_shift, self.flow_shift2])\n",
    "        ])\n",
    "\n",
    "        wan_lora_config = widgets.VBox([\n",
    "            widgets.HBox([self.use_lightx2v, self.lightx2v_Strength]),\n",
    "            widgets.HBox([self.use_lightx2v2, self.lightx2v2_Strength])\n",
    "        ])\n",
    "        \n",
    "        custom_lora_config = widgets.VBox([\n",
    "            widgets.HBox([self.use_lora_1, self.lora_1_strength]),\n",
    "            widgets.HBox([self.use_lora_2, self.lora_2_strength]),\n",
    "            widgets.HBox([self.use_lora_3, self.lora_3_strength])\n",
    "        ])\n",
    "\n",
    "        teacache_settings = widgets.VBox([\n",
    "            self.rel_l1_thresh, self.start_percent, self.end_percent\n",
    "        ])\n",
    "        \n",
    "        interpolation_settings = widgets.VBox([\n",
    "            self.interpolate_video, self.frame_multiplier, self.interpolated_fps, self.crf_value\n",
    "        ])\n",
    "        \n",
    "        upscaling_settings = widgets.VBox([\n",
    "            self.apply_upscaling,\n",
    "            self.upscale_by,\n",
    "            self.upscale_denoise,\n",
    "            self.upscale_steps,\n",
    "            self.upscale_model_name\n",
    "        ])\n",
    "\n",
    "        accordion = widgets.Accordion(children=[\n",
    "            generation_settings,\n",
    "            widgets.VBox([self.model_quant, self.lightx2v_rank]),\n",
    "            lora_downloads,\n",
    "            model_config,\n",
    "            wan_lora_config,\n",
    "            custom_lora_config,\n",
    "            teacache_settings,\n",
    "            interpolation_settings,\n",
    "            upscaling_settings\n",
    "        ])\n",
    "        \n",
    "        accordion.set_title(0, '📝 Video Settings')\n",
    "        accordion.set_title(1, '🤖 Base Model Settings')\n",
    "        accordion.set_title(2, '📥 LoRA Downloads')\n",
    "        accordion.set_title(3, '⚙️ Model Advanced Config')\n",
    "        accordion.set_title(4, '🚀 Wan 2.1 LoRA Config')\n",
    "        accordion.set_title(5, '🎨 Custom LoRA Config')\n",
    "        accordion.set_title(6, '🧠 Teacache Settings')\n",
    "        accordion.set_title(7, '✨ Frame Interpolation')\n",
    "        accordion.set_title(8, '🚀 Video Upscaling')\n",
    "\n",
    "        upload_box = widgets.VBox([self.image_uploader, self.display_upload_check])\n",
    "        \n",
    "        display(widgets.VBox([\n",
    "            widgets.HTML(\"<h1>💥 ComfyUI Video Generation Settings</h1>\"),\n",
    "            widgets.HTML(\"<h3>1. 파일 업로드</h3>\"),\n",
    "            upload_box,\n",
    "            widgets.HTML(\"<hr><h3>2. 생성 옵션</h3>\"),\n",
    "            accordion\n",
    "        ]))\n",
    "\n",
    "# UI 인스턴스 생성 및 표시\n",
    "ui = UI()\n",
    "ui.display_ui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d3c7d-bacf-492c-b95a-7fc6465aeaf2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 셀 2: 사전설정 (오타 수정 최종 버전)\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output, display, HTML, Image as IPImage\n",
    "import random\n",
    "\n",
    "# 1. 라이브러리 설치\n",
    "print(\"Installing required libraries...\")\n",
    "!pip install torch==2.6.0 torchvision==0.21.0\n",
    "!pip install -q torchsde einops diffusers accelerate xformers==0.0.29.post2 triton==3.2.0 sageattention\n",
    "!pip install -q av spandrel albumentations insightface onnx opencv-python segment_anything ultralytics onnxruntime onnxruntime-gpu\n",
    "!apt -y install -qq aria2 ffmpeg\n",
    "clear_output(wait=True)\n",
    "print(\"Library installation complete.\")\n",
    "\n",
    "# 2. ComfyUI 및 커스텀 노드 클론 및 설정\n",
    "print(\"Setting up ComfyUI and custom nodes...\")\n",
    "if not os.path.exists('/content/ComfyUI'):\n",
    "    !git clone https://github.com/comfyanonymous/ComfyUI /content/ComfyUI\n",
    "    %cd /content/ComfyUI/custom_nodes\n",
    "    !git clone https://github.com/city96/ComfyUI-GGUF ComfyUI_GGUF\n",
    "    !git clone https://github.com/kijai/ComfyUI-KJNodes ComfyUI_KJNodes\n",
    "    !git clone https://github.com/Isi-dev/ComfyUI_UltimateSDUpscale ComfyUI_UltimateSDUpscale\n",
    "    %cd /content/ComfyUI/custom_nodes/ComfyUI_GGUF\n",
    "    !pip install -r requirements.txt\n",
    "    %cd /content/ComfyUI/custom_nodes/ComfyUI_KJNodes\n",
    "    !sed -i 's/^/#/' /content/ComfyUI/custom_nodes/ComfyUI_KJNodes/__init__.py\n",
    "    !pip install -r requirements.txt\n",
    "\n",
    "# 3. RIFE 모델 설치\n",
    "if not os.path.exists('/content/Practical-RIFE'):\n",
    "    %cd /content\n",
    "    !git clone https://github.com/Isi-dev/Practical-RIFE\n",
    "    %cd /content/Practical-RIFE\n",
    "    !pip install git+https://github.com/rk-exxec/scikit-video.git@numpy_deprecation\n",
    "    os.makedirs('/content/Practical-RIFE/train_log', exist_ok=True)\n",
    "    !wget -q https://huggingface.co/Isi99999/Frame_Interpolation_Models/resolve/main/4.25/train_log/IFNet_HDv3.py -O /content/Practical-RIFE/train_log/IFNet_HDv3.py\n",
    "    !wget -q https://huggingface.co/Isi99999/Frame_Interpolation_Models/resolve/main/4.25/train_log/RIFE_HDv3.py -O /content/Practical-RIFE/train_log/RIFE_HDv3.py\n",
    "    !wget -q https://huggingface.co/Isi99999/Frame_Interpolation_Models/resolve/main/4.25/train_log/refine.py -O /content/Practical-RIFE/train_log/refine.py\n",
    "    !wget -q https://huggingface.co/Isi99999/Frame_Interpolation_Models/resolve/main/4.25/train_log/flownet.pkl -O /content/Practical-RIFE/train_log/flownet.pkl\n",
    "\n",
    "%cd /content/ComfyUI\n",
    "!sed -i -e 's/^from server import PromptServer/# from server import PromptServer/' -e '/^\\\\\\\\s*if unique_id:/s/^/    # /' -e '/PromptServer\\\\\\\\.instance\\\\\\\\.send_progress_text/s/^/            # /' /content/ComfyUI/comfy_extras/nodes_images.py\n",
    "clear_output(wait=True)\n",
    "print(\"ComfyUI setup complete.\")\n",
    "\n",
    "# 4. 파이썬 환경 설정 및 모듈 임포트\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "sys.path.insert(0, '/content/ComfyUI')\n",
    "\n",
    "from comfy import model_management\n",
    "from nodes import CheckpointLoaderSimple, CLIPLoader, CLIPTextEncode, VAEDecode, VAELoader, KSampler, KSamplerAdvanced, UNETLoader, LoadImage, SaveImage, CLIPVisionLoader, CLIPVisionEncode, LoraLoaderModelOnly, ImageScale, DualCLIPLoader\n",
    "from custom_nodes.ComfyUI_GGUF.nodes import UnetLoaderGGUF\n",
    "from custom_nodes.ComfyUI_KJNodes.nodes.model_optimization_nodes import WanVideoTeaCacheKJ, PathchSageAttentionKJ, WanVideoNAG, SkipLayerGuidanceWanVideo\n",
    "from comfy_extras.nodes_model_advanced import ModelSamplingSD3\n",
    "from comfy_extras.nodes_images import SaveAnimatedWEBP\n",
    "from comfy_extras.nodes_video import SaveWEBM\n",
    "from comfy_extras.nodes_wan import WanImageToVideo\n",
    "from comfy_extras.nodes_upscale_model import UpscaleModelLoader\n",
    "from comfy_extras.nodes_flux import CLIPTextEncodeFlux\n",
    "\n",
    "# --- START OF ALL HELPER FUNCTIONS ---\n",
    "# 5. 유틸리티 함수 정의\n",
    "def download_with_aria2c(link, folder=\"/content/ComfyUI/models/loras\"):\n",
    "    import os\n",
    "    filename = link.split(\"/\")[-1]\n",
    "    command = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {link} -d {folder} -o {filename}\"\n",
    "    print(\"Executing download command:\")\n",
    "    print(command)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    get_ipython().system(command)\n",
    "    return filename\n",
    "\n",
    "def download_civitai_model(civitai_link, civitai_token, folder=\"/content/ComfyUI/models/loras\"):\n",
    "    import os\n",
    "    import time\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    try:\n",
    "        model_id = civitai_link.split(\"/models/\")[1].split(\"?\")[0]\n",
    "    except IndexError:\n",
    "        raise ValueError(\"Invalid Civitai URL format. Please use a link like: https://civitai.com/api/download/models/1523247?...\")\n",
    "    civitai_url = f\"https://civitai.com/api/download/models/{model_id}?type=Model&format=SafeTensor\"\n",
    "    if civitai_token:\n",
    "        civitai_url += f\"&token={civitai_token}\"\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"model_{timestamp}.safetensors\"\n",
    "    full_path = os.path.join(folder, filename)\n",
    "    download_command = f'wget --max-redirect=10 --show-progress \"{civitai_url}\" -O \"{full_path}\"'\n",
    "    print(\"Downloading from Civitai...\")\n",
    "    get_ipython().system(download_command)\n",
    "    local_path = os.path.join(folder, filename)\n",
    "    if os.path.exists(local_path) and os.path.getsize(local_path) > 0:\n",
    "        print(f\"LoRA downloaded successfully: {local_path}\")\n",
    "    else:\n",
    "        print(f\"❌ LoRA download failed or file is empty: {local_path}\")\n",
    "    return filename\n",
    "\n",
    "def download_lora(link, folder=\"/content/ComfyUI/models/loras\", civitai_token=None):\n",
    "    if \"civitai.com\" in link.lower():\n",
    "        if not civitai_token:\n",
    "            raise ValueError(\"Civitai token is required for Civitai downloads\")\n",
    "        return download_civitai_model(link, civitai_token, folder)\n",
    "    else:\n",
    "        return download_with_aria2c(link, folder)\n",
    "\n",
    "def model_download(url: str, dest_dir: str, filename: str = None, silent: bool = True) -> str | bool:\n",
    "    try:\n",
    "        Path(dest_dir).mkdir(parents=True, exist_ok=True)\n",
    "        if filename is None:\n",
    "            filename = url.split('/')[-1].split('?')[0].replace('%20', ' ')\n",
    "        \n",
    "        full_path = Path(dest_dir) / filename\n",
    "        if full_path.exists():\n",
    "            if silent:\n",
    "                print(f\"Skipping {filename} (already exists)...\", end=' ', flush=True)\n",
    "            return filename\n",
    "\n",
    "        cmd = ['aria2c', '--console-log-level=error', '-c', '-x', '16', '-s', '16', '-k', '1M', '-d', dest_dir, '-o', filename, url]\n",
    "        if silent:\n",
    "            cmd.extend(['--summary-interval=0', '--quiet'])\n",
    "            print(f\"Downloading {filename}...\", end=' ', flush=True)\n",
    "        \n",
    "        subprocess.run(cmd, check=True, capture_output=silent, text=True)\n",
    "        \n",
    "        if silent:\n",
    "            print(\"Done!\")\n",
    "        else:\n",
    "            print(f\"Downloaded {filename} to {dest_dir}\")\n",
    "        return filename\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ Error downloading {filename}: {e.stderr.strip() if e.stderr else 'Unknown error'}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ An unexpected error occurred: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def image_width_height(image):\n",
    "    if image.ndim == 4: _, height, width, _ = image.shape\n",
    "    elif image.ndim == 3: height, width, _ = image.shape\n",
    "    else: raise ValueError(f\"Unsupported image shape: {image.shape}\")\n",
    "    return width, height\n",
    "\n",
    "def clear_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache(); torch.cuda.ipc_collect()\n",
    "    gc.collect()\n",
    "\n",
    "def save_as_mp4(images, filename_prefix, fps, output_dir=\"/content/ComfyUI/output\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"{output_dir}/{filename_prefix}.mp4\"\n",
    "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
    "    with imageio.get_writer(output_path, fps=fps, codec='libx264', quality=8) as writer:\n",
    "        for frame in frames: writer.append_data(frame)\n",
    "    return output_path\n",
    "\n",
    "def save_as_image(image, filename_prefix, output_dir=\"/content/ComfyUI/output\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"{output_dir}/{filename_prefix}.png\"\n",
    "    frame = (image.cpu().numpy() * 255).astype(np.uint8)\n",
    "    Image.fromarray(frame).save(output_path)\n",
    "    return output_path\n",
    "\n",
    "def save_as_webm(images, filename_prefix, fps, codec=\"vp9\", quality=32, output_dir=\"/content/ComfyUI/output\"):\n",
    "    os.makedirs(output_dir, exist_ok=True); output_path = f\"{output_dir}/{filename_prefix}.webm\"\n",
    "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
    "    kwargs = {'fps': int(fps), 'quality': int(quality), 'codec': str(codec), 'output_params': ['-crf', str(int(quality))]}\n",
    "    with imageio.get_writer(output_path, format='FFMPEG', mode='I', **kwargs) as writer:\n",
    "        for frame in frames: writer.append_data(frame)\n",
    "    return output_path\n",
    "\n",
    "def display_video(video_path):\n",
    "    from base64 import b64encode\n",
    "    video_data = open(video_path,'rb').read()\n",
    "    mime_type = f\"video/{video_path.split('.')[-1]}\"\n",
    "    data_url = f\"data:{mime_type};base64,\" + b64encode(video_data).decode()\n",
    "    display(HTML(f'<video width=512 controls autoplay loop><source src=\"{data_url}\" type=\"{mime_type}\"></video>'))\n",
    "\n",
    "def swapT(pa, f, s):\n",
    "    return s if pa == f else pa\n",
    "\n",
    "output_path = \"\"\n",
    "output_pathU = \"\"\n",
    "\n",
    "def generate_video(\n",
    "    image_path: str = None,\n",
    "    LoRA_Strength: float = 1.00,\n",
    "    rel_l1_thresh: float = 0.275,\n",
    "    start_percent: float = 0.1,\n",
    "    end_percent: float = 1.0,\n",
    "    positive_prompt: str = \"a cute anime girl\",\n",
    "    negative_prompt: str = \"...\",\n",
    "    width: int = 832,\n",
    "    height: int = 480,\n",
    "    seed: int = 0,\n",
    "    steps: int = 20,\n",
    "    cfg_scale: float = 1.0,\n",
    "    sampler_name: str = \"uni_pc\",\n",
    "    scheduler: str = \"simple\",\n",
    "    frames: int = 33,\n",
    "    fps: int = 16,\n",
    "    output_format: str = \"mp4\",\n",
    "    overwrite: bool = False,\n",
    "    use_lora: bool = True,\n",
    "    use_lora2: bool = True,\n",
    "    LoRA_Strength2: float = 1.00,\n",
    "    use_lora3: bool = True,\n",
    "    LoRA_Strength3: float = 1.00,\n",
    "    use_lightx2v: bool = False,\n",
    "    lightx2v_Strength: float = 0.80,\n",
    "    lightx2v_steps: int = 4,\n",
    "    use_pusa: bool = False, # 'false'를 'False'로 수정\n",
    "    pusa_Strength: float = 1.2,\n",
    "    pusa_steps: int = 6,\n",
    "    use_sage_attention: bool = True,\n",
    "    enable_flow_shift: bool = True,\n",
    "    shift: float = 8.0,\n",
    "    enable_flow_shift2: bool = True,\n",
    "    shift2: float = 8.0,\n",
    "    end_step1: int = 10,\n",
    "    prompt_assist: str = \"none\"\n",
    "):\n",
    "    # 이 함수는 여기서 정의되지만 실제 호출은 나중 셀에서 이루어집니다.\n",
    "    # 이 셀에서는 선언만 해두어 나중에 사용할 수 있도록 합니다.\n",
    "    pass\n",
    "\n",
    "# --- END OF ALL HELPER FUNCTIONS ---\n",
    "\n",
    "# 6. UI 설정에 따라 모델 다운로드\n",
    "try:\n",
    "    print(\"Downloading models based on UI settings...\")\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # LoRA 다운로드\n",
    "    lora_1, lora_2, lora_3 = None, None, None\n",
    "    if ui.download_lora_1.value and ui.lora_1_url.value:\n",
    "        lora_1 = download_lora(ui.lora_1_url.value, civitai_token=ui.civitai_token.value)\n",
    "    if ui.download_lora_2.value and ui.lora_2_url.value:\n",
    "        lora_2 = download_lora(ui.lora_2_url.value, civitai_token=ui.civitai_token.value)\n",
    "    if ui.download_lora_3.value and ui.lora_3_url.value:\n",
    "        lora_3 = download_lora(ui.lora_3_url.value, civitai_token=ui.civitai_token.value)\n",
    "\n",
    "    # lightx2v LoRA URL 결정\n",
    "    if ui.lightx2v_rank.value == \"32\":\n",
    "        lightx2v_url = \"https://huggingface.co/Isi99999/Wan2.1BasedModels/resolve/main/lightx2v_I2V_14B_480p_cfg_step_distill_rank32_bf16.safetensors\"\n",
    "    elif ui.lightx2v_rank.value == \"64\":\n",
    "        lightx2v_url = \"https://huggingface.co/Isi99999/Wan2.1BasedModels/resolve/main/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank64_bf16.safetensors\"\n",
    "    else: # 128\n",
    "        lightx2v_url = \"https://huggingface.co/Isi99999/Wan2.1BasedModels/resolve/main/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank128_bf16.safetensors\"\n",
    "        \n",
    "    models_to_download = {\n",
    "        \"dit_model\": (f\"https://huggingface.co/Isi99999/Wan2.2BasedModels/resolve/main/wan2.2_i2v_high_noise_14B_{ui.model_quant.value}.gguf\", \"/content/ComfyUI/models/diffusion_models\"),\n",
    "        \"dit_model2\": (f\"https://huggingface.co/Isi99999/Wan2.2BasedModels/resolve/main/wan2.2_i2v_low_noise_14B_{ui.model_quant.value}.gguf\", \"/content/ComfyUI/models/diffusion_models\"),\n",
    "        \"text_encoder\": (\"https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors\", \"/content/ComfyUI/models/text_encoders\"),\n",
    "        \"main_vae\": (\"https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors\", \"/content/ComfyUI/models/vae\"),\n",
    "        \"clip_vision\": (\"https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors\", \"/content/ComfyUI/models/clip_vision\"),\n",
    "        \"lightx2v_lora\": (lightx2v_url, \"/content/ComfyUI/models/loras\"),\n",
    "        \"walkingToViewersL\": (\"https://huggingface.co/Isi99999/Wan2.1_14B-480p_I2V_LoRAs/resolve/main/walking%20to%20viewers_Wan.safetensors\", \"/content/ComfyUI/models/loras\"),\n",
    "        \"walkingFromBehindL\": (\"https://huggingface.co/Isi99999/Wan2.1_14B-480p_I2V_LoRAs/resolve/main/walking_from_behind.safetensors\", \"/content/ComfyUI/models/loras\"),\n",
    "        \"dancingL\": (\"https://huggingface.co/Isi99999/Wan2.1_14B-480p_I2V_LoRAs/resolve/main/b3ll13-d8nc3r.safetensors\", \"/content/ComfyUI/models/loras\"),\n",
    "        \"flux_model\": (\"https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/flux1-dev-Q8_0.gguf\", \"/content/ComfyUI/models/unet\"),\n",
    "        \"flux_vae\": (\"https://huggingface.co/lovis93/testllm/resolve/ed9cf1af7465cebca4649157f118e331cf2a084f/ae.safetensors\", \"/content/ComfyUI/models/vae\"),\n",
    "        \"flux_clip_l\": (\"https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors\", \"/content/ComfyUI/models/clip\"),\n",
    "        \"flux_t5xxl\": (\"https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors\", \"/content/ComfyUI/models/clip\"),\n",
    "        \"upscaler_sharp\": (\"https://huggingface.co/lokCX/4x-Ultrasharp/resolve/main/4x-UltraSharp.pth\", \"/content/ComfyUI/models/upscale_models\"),\n",
    "        #\"upscaler_remacri\": (\"https://huggingface.co/Isi-dev/Upscalers/resolve/main/4x_foolhardy_Remacri.pth\", \"/content/ComfyUI/models/upscale_models\"),\n",
    "        #\"upscaler_anime\": (\"https://huggingface.co/Isi-dev/Upscalers/resolve/main/4x-AnimeSharp.pth\", \"/content/ComfyUI/models/upscale_models\"),\n",
    "    }\n",
    "    \n",
    "    download_results = {}\n",
    "    for name, (url, path) in models_to_download.items():\n",
    "        download_results[name] = model_download(url, path)\n",
    "\n",
    "    failed_models = [name for name, result in download_results.items() if not result]\n",
    "    if failed_models:\n",
    "        raise RuntimeError(f\"❌ 다음 필수 모델 다운로드에 실패했습니다: {', '.join(failed_models)}. 셀 2의 출력 로그를 확인하고 다시 실행해주세요.\")\n",
    "    \n",
    "    for name, filename in download_results.items():\n",
    "        globals()[name] = filename\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(\"✅ Environment Setup and Model Download Complete!\")\n",
    "    file_uploaded = None\n",
    "    upscaled_video_path = None\n",
    "\n",
    "except NameError:\n",
    "    print(\"UI object 'ui' is not defined. Skipping UI-based model downloads.\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3559ac9-a648-49da-8248-e507faa79f65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 셀 3: 이미지 업로드 (두 번째 오류 수정 버전)\n",
    "import io\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# UI 위젯에서 업로드된 파일 정보 가져오기\n",
    "uploaded_file_info = ui.image_uploader.value\n",
    "\n",
    "if not uploaded_file_info:\n",
    "    print(\"‼️ 이미지를 먼저 업로드해주세요 (셀 1의 'Upload Image' 버튼 사용).\")\n",
    "else:\n",
    "    # 마지막(첫 번째)으로 업로드된 파일을 사용합니다.\n",
    "    last_uploaded_file = uploaded_file_info[0]\n",
    "    \n",
    "    filename = last_uploaded_file['name']\n",
    "    content = last_uploaded_file['content']\n",
    "    \n",
    "    # 파일 저장\n",
    "    save_dir = '/content/ComfyUI/input'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_uploaded = os.path.join(save_dir, filename)\n",
    "    \n",
    "    with open(file_uploaded, 'wb') as f:\n",
    "        f.write(content)\n",
    "        \n",
    "    print(f\"✅ Image '{filename}' uploaded successfully to '{file_uploaded}'\")\n",
    "    \n",
    "    # 업로드된 이미지 표시 (옵션)\n",
    "    if ui.display_upload_check.value:\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):\n",
    "            img_data = io.BytesIO(content)\n",
    "            img = Image.open(img_data)\n",
    "            display(img)\n",
    "        else:\n",
    "            print(\"Cannot display this file type.\")\n",
    "    \n",
    "    # --- 수정된 부분: 위젯 값을 새로운 빈 튜플로 설정하여 초기화 ---\n",
    "    ui.image_uploader.value = ()\n",
    "    \n",
    "    # 위젯의 내부 상태도 초기화하여 재업로드가 가능하게 함\n",
    "    ui.image_uploader._counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a23e23-d4c5-4776-a415-c82183bb3234",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 셀 4: 비디오 생성\n",
    "import time\n",
    "import random\n",
    "\n",
    "if file_uploaded is None:\n",
    "    print(\"‼️ 이미지가 업로드되지 않았습니다. 셀 3을 먼저 실행해주세요.\")\n",
    "else:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # --- UI 값 가져오기 ---\n",
    "    # 비디오 설정\n",
    "    positive_prompt_val = ui.positive_prompt.value\n",
    "    prompt_assist_val = ui.prompt_assist.value\n",
    "    prompt_assist_swap = swapT(prompt_assist_val, \"walking to camera\", \"walking to viewers\")\n",
    "    prompt_assist_swap = swapT(prompt_assist_swap, \"walking from camera\", \"walking from behind\")\n",
    "    prompt_assist_swap = swapT(prompt_assist_swap, \"swaying\", \"b3ll13-d8nc3r\")\n",
    "    final_positive_prompt = f\"{positive_prompt_val} {prompt_assist_swap}.\" if prompt_assist_swap != \"none\" else positive_prompt_val\n",
    "\n",
    "    # 시드 설정\n",
    "    seed_val = ui.seed.value\n",
    "    if seed_val == 0:\n",
    "        seed_val = random.randint(0, 2**32 - 1)\n",
    "    print(f\"Using seed: {seed_val}\")\n",
    "    print(f\"prompt: {final_positive_prompt}\")\n",
    "    # 생성 함수 호출\n",
    "    generate_video(\n",
    "        image_path=file_uploaded,\n",
    "        LoRA_Strength=ui.lora_1_strength.value,\n",
    "        rel_l1_thresh=ui.rel_l1_thresh.value,\n",
    "        start_percent=ui.start_percent.value,\n",
    "        end_percent=ui.end_percent.value,\n",
    "        positive_prompt=final_positive_prompt,\n",
    "        prompt_assist=prompt_assist_swap,\n",
    "        negative_prompt=ui.negative_prompt.value,\n",
    "        width=ui.width.value,\n",
    "        height=ui.height.value,\n",
    "        seed=seed_val,\n",
    "        steps=ui.steps.value,\n",
    "        cfg_scale=ui.cfg_scale.value,\n",
    "        sampler_name=ui.sampler_name.value,\n",
    "        scheduler=ui.scheduler.value,\n",
    "        frames=ui.frames.value,\n",
    "        fps=16, # 하드코딩된 값\n",
    "        output_format=\"mp4\", # 하드코딩된 값\n",
    "        overwrite=ui.overwrite_previous_video.value,\n",
    "        use_lora=ui.use_lora_1.value,\n",
    "        use_lora2=ui.use_lora_2.value,\n",
    "        LoRA_Strength2=ui.lora_2_strength.value,\n",
    "        use_lora3=ui.use_lora_3.value,\n",
    "        LoRA_Strength3=ui.lora_3_strength.value,\n",
    "        use_lightx2v=ui.use_lightx2v.value,\n",
    "        lightx2v_Strength=ui.lightx2v_Strength.value,\n",
    "        lightx2v_steps=ui.steps.value, # steps 값으로 설정\n",
    "        use_pusa=ui.use_lightx2v2.value,\n",
    "        pusa_Strength=ui.lightx2v2_Strength.value,\n",
    "        pusa_steps=ui.steps.value, # steps 값으로 설정\n",
    "        use_sage_attention=ui.use_sage_attention.value,\n",
    "        enable_flow_shift=ui.use_flow_shift.value,\n",
    "        shift=ui.flow_shift.value,\n",
    "        enable_flow_shift2=ui.use_flow_shift.value,\n",
    "        shift2=ui.flow_shift2.value,\n",
    "        end_step1=ui.high_noise_steps.value\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    mins, secs = divmod(duration, 60)\n",
    "    print(f\"Seed: {seed_val}\")\n",
    "    print(f\"✅ Generation completed in {int(mins)} min {secs:.2f} sec\")\n",
    "\n",
    "    clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b5144-1d2c-46cc-bb22-ed92d87399c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 셀 5: 프레임 보간 (Frame Interpolation)\n",
    "import glob\n",
    "import time\n",
    "\n",
    "if not ui.interpolate_video.value:\n",
    "    print(\"☑️ Frame interpolation skipped as per UI setting.\")\n",
    "elif not output_path or not os.path.exists(output_path):\n",
    "    print(\"‼️ No video file found from the previous step. Cannot interpolate.\")\n",
    "else:\n",
    "    print(\"✨ Applying Frame Interpolation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # UI에서 값 가져오기\n",
    "    frame_multiplier_val = ui.frame_multiplier.value\n",
    "    interpolated_fps_val = ui.interpolated_fps.value\n",
    "    crf_val = ui.crf_value.value\n",
    "\n",
    "    print(f\"Original video path: {output_path}\")\n",
    "    print(f\"Converting video. Multiplier: {frame_multiplier_val}x, Target FPS: {interpolated_fps_val}, CRF: {crf_val}\")\n",
    "\n",
    "    # os.chdir 대신 %cd 매직 커맨드 사용\n",
    "    %cd /content/Practical-RIFE\n",
    "    \n",
    "    # 추론 스크립트 실행 (os.system 대신 ! 사용)\n",
    "    inference_command = f\"python3 inference_video.py --multi={frame_multiplier_val} --fps={interpolated_fps_val} --video='{output_path}' --scale=1\"\n",
    "    !{inference_command}\n",
    "\n",
    "    # 결과 파일 찾기 및 변환\n",
    "    video_folder = \"/content/ComfyUI/output/\"\n",
    "    # RIFE는 원본 파일명에 _[multiplier]x.mp4 를 추가하여 저장합니다.\n",
    "    base_name = os.path.splitext(os.path.basename(output_path))[0]\n",
    "    interpolated_video_path = os.path.join(video_folder, f\"{base_name}_{frame_multiplier_val}X_30fps.mp4\")\n",
    "\n",
    "    if os.path.exists(interpolated_video_path):\n",
    "        final_output_path = \"/content/Practical-RIFE/output_converted.mp4\"\n",
    "        # ffmpeg 명령어 실행 (os.system 대신 ! 사용)\n",
    "        ffmpeg_command = f\"ffmpeg -i '{interpolated_video_path}' -vcodec libx264 -crf {crf_val} -preset fast '{final_output_path}' -loglevel error -y\"\n",
    "        !{ffmpeg_command}\n",
    "        \n",
    "        print(f\"Displaying final video: {final_output_path}\")\n",
    "        display_video(final_output_path)\n",
    "    else:\n",
    "        print(f\"❌ Interpolated video not found at expected path: {interpolated_video_path}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    mins, secs = divmod(duration, 60)\n",
    "    print(f\"✅ Frame Interpolation completed in {int(mins)} min {secs:.2f} sec\")\n",
    "\n",
    "    clear_memory()\n",
    "    # 작업 후 원래 디렉토리로 돌아감\n",
    "    %cd /content/ComfyUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3051c1ca-08b8-4995-b0a6-ca10aa082599",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 셀 6: 비디오 업스케일링 (Flux Upscaler)\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "from custom_nodes.ComfyUI_UltimateSDUpscale.nodes import UltimateSDUpscale\n",
    "output_path = \"/content/ComfyUI/output/ComfyUI.mp4\"\n",
    "# --- 경로 문제 해결을 위한 코드 시작 ---\n",
    "# ComfyUI 디렉토리를 Python 경로에 추가하여 커스텀 노드를 찾을 수 있도록 합니다.\n",
    "comfyui_path = '/content/ComfyUI'\n",
    "\n",
    "if comfyui_path not in sys.path:\n",
    "    sys.path.insert(0, comfyui_path)\n",
    "    print(f\"'{comfyui_path}' 경로를 추가했습니다.\")\n",
    "\n",
    "# 경로 추가 후 모듈을 임포트합니다.\n",
    "try:\n",
    "    from custom_nodes.ComfyUI_UltimateSDUpscale.nodes import UltimateSDUpscale\n",
    "except (ImportError, ModuleNotFoundError) as e:\n",
    "    print(\"❌ 모듈 임포트 실패: 셀 2(사전설정)가 올바르게 실행되었는지 다시 확인해주세요.\")\n",
    "    # git clone으로 생성되어야 할 폴더가 있는지 직접 확인\n",
    "    expected_path = os.path.join(comfyui_path, 'custom_nodes', 'ComfyUI_UltimateSDUpscale')\n",
    "    if not os.path.exists(expected_path):\n",
    "        print(f\"👉 확인 결과: '{expected_path}' 디렉토리가 없습니다. 셀 2를 다시 실행하여 커스텀 노드를 다운로드하세요.\")\n",
    "    raise e # 원래 오류를 다시 발생시켜 셀 실행을 중지\n",
    "# --- 경로 문제 해결을 위한 코드 끝 ---\n",
    "\n",
    "\n",
    "# 업스케일링에 필요한 헬퍼 함수\n",
    "def extract_frames(video_path):\n",
    "    \"\"\"비디오에서 프레임과 FPS를 추출합니다.\"\"\"\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    frames = []\n",
    "    print(f\"Extracting frames from {os.path.basename(video_path)}...\")\n",
    "    while True:\n",
    "        success, frame = vidcap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "    print(f\"Extracted {len(frames)} frames at {fps:.2f} FPS\")\n",
    "    return frames, fps\n",
    "\n",
    "# --- 메인 업스케일링 로직 ---\n",
    "if not ui.apply_upscaling.value:\n",
    "    print(\"☑️ Video upscaling skipped as per UI setting.\")\n",
    "else:\n",
    "    # 5번 셀(프레임 보간)의 결과물 우선 탐색, 없으면 4번 셀(비디오 생성) 결과물 사용\n",
    "    video_to_upscale = None\n",
    "    try:\n",
    "        # 'final_output_path'는 5번 셀의 결과 변수명, 'output_path'는 4번 셀의 결과 변수명입니다.\n",
    "        if 'final_output_path' in globals() and final_output_path and os.path.exists(final_output_path):\n",
    "            video_to_upscale = final_output_path\n",
    "            print(f\"Found interpolated video to upscale: {video_to_upscale}\")\n",
    "        elif 'output_path' in globals() and output_path and os.path.exists(output_path):\n",
    "            video_to_upscale = output_path\n",
    "            print(f\"Found generated video to upscale: {video_to_upscale}\")\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "    if not video_to_upscale:\n",
    "        print(\"‼️ No video file found from previous steps. Cannot upscale.\")\n",
    "    else:\n",
    "        print(f\"✨ Starting video upscale for: {os.path.basename(video_to_upscale)}\")\n",
    "        start_time = time.time()\n",
    "        clear_memory()\n",
    "\n",
    "        # ComfyUI 노드 인스턴스 생성\n",
    "        clip_loader_upscale = DualCLIPLoader()\n",
    "        unet_loader_upscale = UnetLoaderGGUF()\n",
    "        vae_loader_upscale = VAELoader()\n",
    "        upscale_model_loader = UpscaleModelLoader()\n",
    "        positive_prompt_encode = CLIPTextEncodeFlux()\n",
    "        negative_prompt_encode = CLIPTextEncodeFlux()\n",
    "        upscaler_node = UltimateSDUpscale()\n",
    "        load_image_node = LoadImage()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            # 모델 로딩\n",
    "            print(\"Loading FLUX models for upscaling...\")\n",
    "            clip = clip_loader_upscale.load_clip(flux_t5xxl, flux_clip_l, \"flux\")[0]\n",
    "            # 업스케일링 시 프롬프트는 비워두어 원본을 최대한 유지\n",
    "            positive = positive_prompt_encode.encode(clip, \"\", \"\", 3.5)[0]\n",
    "            negative = negative_prompt_encode.encode(clip, \"\", \"\", 3.5)[0]\n",
    "            del clip\n",
    "            \n",
    "            model = unet_loader_upscale.load_unet(flux_model)[0]\n",
    "            vae = vae_loader_upscale.load_vae(flux_vae)[0]\n",
    "            upscale_model = upscale_model_loader.load_model(ui.upscale_model_name.value)[0]\n",
    "\n",
    "            # 프레임 추출\n",
    "            frames, fps = extract_frames(video_to_upscale)\n",
    "            upscaled_frames = []\n",
    "\n",
    "            # 프레임별 업스케일링\n",
    "            for i, frame_array in enumerate(frames):\n",
    "                print(f\"Upscaling frame {i+1}/{len(frames)}...\")\n",
    "                # 메모리 내에서 처리하기 위해 PIL Image로 변환 후 텐서로 변환\n",
    "                pil_image = Image.fromarray(frame_array)\n",
    "                image_tensor = torch.from_numpy(np.array(pil_image).astype(np.float32) / 255.0).unsqueeze(0)\n",
    "\n",
    "                # UltimateSDUpscale 노드 실행\n",
    "                upscaled_frame_tensor = upscaler_node.upscale(\n",
    "                    image=image_tensor, model=model, positive=positive, negative=negative, vae=vae,\n",
    "                    upscale_by=ui.upscale_by.value, seed=random.randint(0, 2**32 - 1), steps=ui.upscale_steps.value, cfg=1.0,\n",
    "                    sampler_name=\"dpmpp_2m\", scheduler=\"karras\", denoise=ui.upscale_denoise.value,\n",
    "                    upscale_model=upscale_model, mode_type=\"Linear\", tile_width=1024, tile_height=1024,\n",
    "                    mask_blur=8, tile_padding=32, seam_fix_mode=\"None\", seam_fix_denoise=1.0,\n",
    "                    seam_fix_width=64, seam_fix_mask_blur=8, seam_fix_padding=16, force_uniform_tiles=True,\n",
    "                    tiled_decode=False\n",
    "                )[0]\n",
    "                upscaled_frames.append(upscaled_frame_tensor)\n",
    "\n",
    "            # 메모리 정리\n",
    "            del model, vae, upscale_model, positive, negative\n",
    "            clear_memory()\n",
    "\n",
    "            # 업스케일된 비디오 저장 및 표시\n",
    "            if upscaled_frames:\n",
    "                print(\"Saving upscaled video...\")\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                upscaled_filename = f\"Upscaled_{timestamp}\"\n",
    "                upscaled_video_path = save_as_mp4(upscaled_frames, upscaled_filename, fps)\n",
    "                display_video(upscaled_video_path)\n",
    "\n",
    "                end_time = time.time()\n",
    "                duration = end_time - start_time\n",
    "                mins, secs = divmod(duration, 60)\n",
    "                print(f\"✅ Upscaling completed in {int(mins)} min {secs:.2f} sec\")\n",
    "            else:\n",
    "                print(\"❌ Upscaling failed, no frames were processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31c45b3-5894-4be2-b2ec-3304981b727b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 셀 7: 파일 삭제\n",
    "!rm -R /content/ComfyUI/input/*\n",
    "!rm -R /content/ComfyUI/output/*\n",
    "print(\"삭제완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b0ddb-cdf8-434a-9a9a-9b1192131297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
