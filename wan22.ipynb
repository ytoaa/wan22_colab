{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c3eb4d-d9a1-47c5-b881-c380c2e7d3cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ì…€ 1: ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ (UI) ì„¤ì •\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Google Colabì˜ displayì™€ ipywidgetsì˜ displayê°€ ì¶©ëŒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ëª…ì‹œì ìœ¼ë¡œ ìŠ¤íƒ€ì¼ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "display(HTML(\"<style>.widget-label { min-width: 25ex !important; }</style>\"))\n",
    "\n",
    "class UI:\n",
    "    def __init__(self):\n",
    "        # --- ëª¨ë¸ ì„¤ì • ---\n",
    "        self.model_quant = widgets.Dropdown(options=[\"Q4_K_M\", \"Q5_K_M\", \"Q6_K\", \"Q8_0\"], value=\"Q4_K_M\", description=\"Model Quantization:\")\n",
    "        self.lightx2v_rank = widgets.Dropdown(options=[\"32\", \"64\", \"128\"], value=\"32\", description=\"Lightx2v Rank:\")\n",
    "\n",
    "        # --- LoRA ë‹¤ìš´ë¡œë“œ ì„¤ì • ---\n",
    "        self.download_lora_1 = widgets.Checkbox(value=False, description=\"Download LoRA 1\")\n",
    "        self.lora_1_url = widgets.Text(value=\"Put your LoRA URL here\", description=\"LoRA 1 URL:\")\n",
    "        self.download_lora_2 = widgets.Checkbox(value=False, description=\"Download LoRA 2\")\n",
    "        self.lora_2_url = widgets.Text(value=\"Put your LoRA URL here\", description=\"LoRA 2 URL:\")\n",
    "        self.download_lora_3 = widgets.Checkbox(value=False, description=\"Download LoRA 3\")\n",
    "        self.lora_3_url = widgets.Text(value=\"https://huggingface.co/Remade-AI/Rotate/resolve/main/rotate_20_epochs.safetensors\", description=\"LoRA 3 URL:\")\n",
    "        self.civitai_token = widgets.Password(description=\"Civitai Token:\", value=\"\")\n",
    "\n",
    "        # --- ë¹„ë””ì˜¤ ìƒì„± ì„¤ì • ---\n",
    "        self.positive_prompt = widgets.Textarea(value=\"slow jumping and fast dancing\", description=\"Positive Prompt:\", layout={'width': '95%', 'height': '80px'})\n",
    "        self.prompt_assist = widgets.Dropdown(options=[\"none\", \"walking to camera\", \"walking from camera\", \"swaying\"], value=\"none\", description=\"Prompt Assist:\")\n",
    "        self.negative_prompt = widgets.Textarea(value=\"è‰²è°ƒè‰³ä¸½ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°\", description=\"Negative Prompt:\", layout={'width': '95%', 'height': '80px'})\n",
    "        self.width = widgets.IntText(value=480, description=\"Width:\")\n",
    "        self.height = widgets.IntText(value=720, description=\"Height:\")\n",
    "        self.seed = widgets.IntText(value=0, description=\"Seed (0=random):\")\n",
    "        self.high_noise_steps = widgets.IntSlider(value=3, min=1, max=25, step=1, description=\"High Noise Steps:\")\n",
    "        self.steps = widgets.IntSlider(value=6, min=1, max=50, step=1, description=\"Total Steps:\")\n",
    "        self.cfg_scale = widgets.FloatSlider(value=1.0, min=1.0, max=20.0, step=0.1, description=\"CFG Scale:\")\n",
    "        self.sampler_name = widgets.Dropdown(options=[\"uni_pc\", \"uni_pc_bh2\", \"ddim\",\"euler\", \"euler_cfg_pp\", \"euler_ancestral\", \"euler_ancestral_cfg_pp\", \"heun\", \"heunpp2\",\"dpm_2\", \"dpm_2_ancestral\",\"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_2s_ancestral_cfg_pp\", \"dpmpp_sde\", \"dpmpp_sde_gpu\",\"dpmpp_2m\", \"dpmpp_2m_cfg_pp\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"dpmpp_3m_sde\", \"dpmpp_3m_sde_gpu\", \"ddpm\", \"lcm\",\"ipndm\", \"ipndm_v\", \"deis\", \"res_multistep\", \"res_multistep_cfg_pp\", \"res_multistep_ancestral\", \"res_multistep_ancestral_cfg_pp\",\"gradient_estimation\", \"er_sde\", \"seeds_2\", \"seeds_3\"], value=\"euler\", description=\"Sampler:\")\n",
    "        self.scheduler = widgets.Dropdown(options=[\"simple\",\"normal\",\"karras\",\"exponential\",\"sgm_uniform\",\"ddim_uniform\",\"beta\",\"linear_quadratic\",\"kl_optimal\"], value=\"simple\", description=\"Scheduler:\")\n",
    "        self.frames = widgets.IntSlider(value=81, min=1, max=120, step=1, description=\"Frames:\")\n",
    "        self.overwrite_previous_video = widgets.Checkbox(value=True, description=\"Overwrite Previous Video\")\n",
    "\n",
    "        # --- ëª¨ë¸ ê³ ê¸‰ ì„¤ì • ---\n",
    "        self.use_sage_attention = widgets.Checkbox(value=True, description=\"Use Sage Attention:\")\n",
    "        self.use_flow_shift = widgets.Checkbox(value=True, description=\"Use Flow Shift:\")\n",
    "        self.flow_shift = widgets.FloatSlider(value=8.0, min=0.0, max=100.0, step=0.01, description=\"Flow Shift 1:\")\n",
    "        self.flow_shift2 = widgets.FloatSlider(value=8.0, min=0.0, max=100.0, step=0.01, description=\"Flow Shift 2:\")\n",
    "\n",
    "        # --- Wan 2.1 LoRA ì„¤ì • ---\n",
    "        self.use_lightx2v = widgets.Checkbox(value=True, description=\"Use Lightx2v:\")\n",
    "        self.lightx2v_Strength = widgets.FloatSlider(value=3.0, min=-10.0, max=10.0, step=0.01, description=\"Lightx2v Strength:\")\n",
    "        self.use_lightx2v2 = widgets.Checkbox(value=True, description=\"Use Lightx2v2 (Pusa):\")\n",
    "        self.lightx2v2_Strength = widgets.FloatSlider(value=1.5, min=-10.0, max=10.0, step=0.01, description=\"Lightx2v2 Strength:\")\n",
    "\n",
    "        # --- ì»¤ìŠ¤í…€ LoRA ì„¤ì • ---\n",
    "        self.use_lora_1 = widgets.Checkbox(value=False, description=\"Use Custom LoRA 1:\")\n",
    "        self.lora_1_strength = widgets.FloatSlider(value=1.0, min=-10.0, max=10.0, step=0.01, description=\"LoRA 1 Strength:\")\n",
    "        self.use_lora_2 = widgets.Checkbox(value=False, description=\"Use Custom LoRA 2:\")\n",
    "        self.lora_2_strength = widgets.FloatSlider(value=1.0, min=-10.0, max=10.0, step=0.01, description=\"LoRA 2 Strength:\")\n",
    "        self.use_lora_3 = widgets.Checkbox(value=False, description=\"Use Custom LoRA 3:\")\n",
    "        self.lora_3_strength = widgets.FloatSlider(value=1.0, min=-10.0, max=10.0, step=0.01, description=\"LoRA 3 Strength:\")\n",
    "\n",
    "        # --- Teacache ì„¤ì • ---\n",
    "        self.rel_l1_thresh = widgets.FloatSlider(value=0, min=0.0, max=10.0, step=0.001, description=\"Rel L1 Thresh:\")\n",
    "        self.start_percent = widgets.FloatSlider(value=0.2, min=0.0, max=1.0, step=0.01, description=\"Start Percent:\")\n",
    "        self.end_percent = widgets.FloatSlider(value=1.0, min=0.0, max=1.0, step=0.01, description=\"End Percent:\")\n",
    "        \n",
    "        # --- í”„ë ˆì„ ë³´ê°„ ì„¤ì • ---\n",
    "        self.interpolate_video = widgets.Checkbox(value=True, description=\"Apply Frame Interpolation\")\n",
    "        self.frame_multiplier = widgets.IntText(value=2, description=\"Frame Multiplier:\")\n",
    "        self.interpolated_fps = widgets.IntText(value=30, description=\"Interpolated FPS:\")\n",
    "        self.crf_value = widgets.IntSlider(value=17, min=0, max=51, step=1, description=\"CRF (Quality):\")\n",
    "        \n",
    "        # --- ì—…ìŠ¤ì¼€ì¼ ì„¤ì • ---\n",
    "        self.apply_upscaling = widgets.Checkbox(value=True, description=\"Apply Upscaling\")\n",
    "        self.upscale_by = widgets.FloatSlider(value=2.0, min=1.0, max=4.0, step=0.1, description=\"Upscale By:\")\n",
    "        self.upscale_denoise = widgets.FloatSlider(value=0.2, min=0.0, max=1.0, step=0.01, description=\"Denoise:\")\n",
    "        self.upscale_steps = widgets.IntSlider(value=20, min=1, max=100, step=1, description=\"Steps:\")\n",
    "        self.upscale_model_name = widgets.Dropdown(\n",
    "            options=[\"4x-UltraSharp.pth\", \"4x_foolhardy_Remacri.pth\", \"4x-AnimeSharp.pth\"],\n",
    "            value=\"4x-UltraSharp.pth\",\n",
    "            description=\"Upscale Model:\"\n",
    "        )\n",
    "\n",
    "        # --- íŒŒì¼ ì—…ë¡œë“œ ---\n",
    "        self.image_uploader = widgets.FileUpload(accept='image/*', description='Upload Image')\n",
    "        self.display_upload_check = widgets.Checkbox(value=False, description=\"Display uploaded image\")\n",
    "\n",
    "\n",
    "    def display_ui(self):\n",
    "        lora_downloads = widgets.VBox([\n",
    "            self.download_lora_1, self.lora_1_url,\n",
    "            self.download_lora_2, self.lora_2_url,\n",
    "            self.download_lora_3, self.lora_3_url,\n",
    "            self.civitai_token\n",
    "        ])\n",
    "        \n",
    "        generation_settings = widgets.VBox([\n",
    "            self.positive_prompt, self.prompt_assist, self.negative_prompt,\n",
    "            widgets.HBox([self.width, self.height]),\n",
    "            self.seed, self.high_noise_steps, self.steps, self.cfg_scale,\n",
    "            self.sampler_name, self.scheduler, self.frames, self.overwrite_previous_video\n",
    "        ])\n",
    "        \n",
    "        model_config = widgets.VBox([\n",
    "            self.use_sage_attention,\n",
    "            widgets.HBox([self.use_flow_shift, self.flow_shift, self.flow_shift2])\n",
    "        ])\n",
    "\n",
    "        wan_lora_config = widgets.VBox([\n",
    "            widgets.HBox([self.use_lightx2v, self.lightx2v_Strength]),\n",
    "            widgets.HBox([self.use_lightx2v2, self.lightx2v2_Strength])\n",
    "        ])\n",
    "        \n",
    "        custom_lora_config = widgets.VBox([\n",
    "            widgets.HBox([self.use_lora_1, self.lora_1_strength]),\n",
    "            widgets.HBox([self.use_lora_2, self.lora_2_strength]),\n",
    "            widgets.HBox([self.use_lora_3, self.lora_3_strength])\n",
    "        ])\n",
    "\n",
    "        teacache_settings = widgets.VBox([\n",
    "            self.rel_l1_thresh, self.start_percent, self.end_percent\n",
    "        ])\n",
    "        \n",
    "        interpolation_settings = widgets.VBox([\n",
    "            self.interpolate_video, self.frame_multiplier, self.interpolated_fps, self.crf_value\n",
    "        ])\n",
    "        \n",
    "        upscaling_settings = widgets.VBox([\n",
    "            self.apply_upscaling,\n",
    "            self.upscale_by,\n",
    "            self.upscale_denoise,\n",
    "            self.upscale_steps,\n",
    "            self.upscale_model_name\n",
    "        ])\n",
    "\n",
    "        accordion = widgets.Accordion(children=[\n",
    "            generation_settings,\n",
    "            widgets.VBox([self.model_quant, self.lightx2v_rank]),\n",
    "            lora_downloads,\n",
    "            model_config,\n",
    "            wan_lora_config,\n",
    "            custom_lora_config,\n",
    "            teacache_settings,\n",
    "            interpolation_settings,\n",
    "            upscaling_settings\n",
    "        ])\n",
    "        \n",
    "        accordion.set_title(0, 'ğŸ“ Video Settings')\n",
    "        accordion.set_title(1, 'ğŸ¤– Base Model Settings')\n",
    "        accordion.set_title(2, 'ğŸ“¥ LoRA Downloads')\n",
    "        accordion.set_title(3, 'âš™ï¸ Model Advanced Config')\n",
    "        accordion.set_title(4, 'ğŸš€ Wan 2.1 LoRA Config')\n",
    "        accordion.set_title(5, 'ğŸ¨ Custom LoRA Config')\n",
    "        accordion.set_title(6, 'ğŸ§  Teacache Settings')\n",
    "        accordion.set_title(7, 'âœ¨ Frame Interpolation')\n",
    "        accordion.set_title(8, 'ğŸš€ Video Upscaling')\n",
    "\n",
    "        upload_box = widgets.VBox([self.image_uploader, self.display_upload_check])\n",
    "        \n",
    "        display(widgets.VBox([\n",
    "            widgets.HTML(\"<h1>ğŸ’¥ ComfyUI Video Generation Settings</h1>\"),\n",
    "            widgets.HTML(\"<h3>1. íŒŒì¼ ì—…ë¡œë“œ</h3>\"),\n",
    "            upload_box,\n",
    "            widgets.HTML(\"<hr><h3>2. ìƒì„± ì˜µì…˜</h3>\"),\n",
    "            accordion\n",
    "        ]))\n",
    "\n",
    "# UI ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° í‘œì‹œ\n",
    "ui = UI()\n",
    "ui.display_ui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d3c7d-bacf-492c-b95a-7fc6465aeaf2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ì…€ 2: ì‚¬ì „ì„¤ì • (ì˜¤íƒ€ ìˆ˜ì • ìµœì¢… ë²„ì „)\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output, display, HTML, Image as IPImage\n",
    "import random\n",
    "\n",
    "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "print(\"Installing required libraries...\")\n",
    "!pip install torch==2.6.0 torchvision==0.21.0\n",
    "!pip install -q torchsde einops diffusers accelerate xformers==0.0.29.post2 triton==3.2.0 sageattention\n",
    "!pip install -q av spandrel albumentations insightface onnx opencv-python segment_anything ultralytics onnxruntime onnxruntime-gpu\n",
    "!apt -y install -qq aria2 ffmpeg\n",
    "clear_output(wait=True)\n",
    "print(\"Library installation complete.\")\n",
    "\n",
    "# 2. ComfyUI ë° ì»¤ìŠ¤í…€ ë…¸ë“œ í´ë¡  ë° ì„¤ì •\n",
    "print(\"Setting up ComfyUI and custom nodes...\")\n",
    "if not os.path.exists('/content/ComfyUI'):\n",
    "    !git clone https://github.com/comfyanonymous/ComfyUI /content/ComfyUI\n",
    "    %cd /content/ComfyUI/custom_nodes\n",
    "    !git clone https://github.com/city96/ComfyUI-GGUF ComfyUI_GGUF\n",
    "    !git clone https://github.com/kijai/ComfyUI-KJNodes ComfyUI_KJNodes\n",
    "    !git clone https://github.com/Isi-dev/ComfyUI_UltimateSDUpscale ComfyUI_UltimateSDUpscale\n",
    "    %cd /content/ComfyUI/custom_nodes/ComfyUI_GGUF\n",
    "    !pip install -r requirements.txt\n",
    "    %cd /content/ComfyUI/custom_nodes/ComfyUI_KJNodes\n",
    "    !sed -i 's/^/#/' /content/ComfyUI/custom_nodes/ComfyUI_KJNodes/__init__.py\n",
    "    !pip install -r requirements.txt\n",
    "\n",
    "# 3. RIFE ëª¨ë¸ ì„¤ì¹˜\n",
    "if not os.path.exists('/content/Practical-RIFE'):\n",
    "    %cd /content\n",
    "    !git clone https://github.com/Isi-dev/Practical-RIFE\n",
    "    %cd /content/Practical-RIFE\n",
    "    !pip install git+https://github.com/rk-exxec/scikit-video.git@numpy_deprecation\n",
    "    os.makedirs('/content/Practical-RIFE/train_log', exist_ok=True)\n",
    "    !wget -q https://huggingface.co/Isi99999/Frame_Interpolation_Models/resolve/main/4.25/train_log/IFNet_HDv3.py -O /content/Practical-RIFE/train_log/IFNet_HDv3.py\n",
    "    !wget -q https://huggingface.co/Isi99999/Frame_Interpolation_Models/resolve/main/4.25/train_log/RIFE_HDv3.py -O /content/Practical-RIFE/train_log/RIFE_HDv3.py\n",
    "    !wget -q https://huggingface.co/Isi99999/Frame_Interpolation_Models/resolve/main/4.25/train_log/refine.py -O /content/Practical-RIFE/train_log/refine.py\n",
    "    !wget -q https://huggingface.co/Isi99999/Frame_Interpolation_Models/resolve/main/4.25/train_log/flownet.pkl -O /content/Practical-RIFE/train_log/flownet.pkl\n",
    "\n",
    "%cd /content/ComfyUI\n",
    "!sed -i -e 's/^from server import PromptServer/# from server import PromptServer/' -e '/^\\\\\\\\s*if unique_id:/s/^/    # /' -e '/PromptServer\\\\\\\\.instance\\\\\\\\.send_progress_text/s/^/            # /' /content/ComfyUI/comfy_extras/nodes_images.py\n",
    "clear_output(wait=True)\n",
    "print(\"ComfyUI setup complete.\")\n",
    "\n",
    "# 4. íŒŒì´ì¬ í™˜ê²½ ì„¤ì • ë° ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "sys.path.insert(0, '/content/ComfyUI')\n",
    "\n",
    "from comfy import model_management\n",
    "from nodes import CheckpointLoaderSimple, CLIPLoader, CLIPTextEncode, VAEDecode, VAELoader, KSampler, KSamplerAdvanced, UNETLoader, LoadImage, SaveImage, CLIPVisionLoader, CLIPVisionEncode, LoraLoaderModelOnly, ImageScale, DualCLIPLoader\n",
    "from custom_nodes.ComfyUI_GGUF.nodes import UnetLoaderGGUF\n",
    "from custom_nodes.ComfyUI_KJNodes.nodes.model_optimization_nodes import WanVideoTeaCacheKJ, PathchSageAttentionKJ, WanVideoNAG, SkipLayerGuidanceWanVideo\n",
    "from comfy_extras.nodes_model_advanced import ModelSamplingSD3\n",
    "from comfy_extras.nodes_images import SaveAnimatedWEBP\n",
    "from comfy_extras.nodes_video import SaveWEBM\n",
    "from comfy_extras.nodes_wan import WanImageToVideo\n",
    "from comfy_extras.nodes_upscale_model import UpscaleModelLoader\n",
    "from comfy_extras.nodes_flux import CLIPTextEncodeFlux\n",
    "\n",
    "# --- START OF ALL HELPER FUNCTIONS ---\n",
    "# 5. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜\n",
    "def download_with_aria2c(link, folder=\"/content/ComfyUI/models/loras\"):\n",
    "    import os\n",
    "    filename = link.split(\"/\")[-1]\n",
    "    command = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {link} -d {folder} -o {filename}\"\n",
    "    print(\"Executing download command:\")\n",
    "    print(command)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    get_ipython().system(command)\n",
    "    return filename\n",
    "\n",
    "def download_civitai_model(civitai_link, civitai_token, folder=\"/content/ComfyUI/models/loras\"):\n",
    "    import os\n",
    "    import time\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    try:\n",
    "        model_id = civitai_link.split(\"/models/\")[1].split(\"?\")[0]\n",
    "    except IndexError:\n",
    "        raise ValueError(\"Invalid Civitai URL format. Please use a link like: https://civitai.com/api/download/models/1523247?...\")\n",
    "    civitai_url = f\"https://civitai.com/api/download/models/{model_id}?type=Model&format=SafeTensor\"\n",
    "    if civitai_token:\n",
    "        civitai_url += f\"&token={civitai_token}\"\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"model_{timestamp}.safetensors\"\n",
    "    full_path = os.path.join(folder, filename)\n",
    "    download_command = f'wget --max-redirect=10 --show-progress \"{civitai_url}\" -O \"{full_path}\"'\n",
    "    print(\"Downloading from Civitai...\")\n",
    "    get_ipython().system(download_command)\n",
    "    local_path = os.path.join(folder, filename)\n",
    "    if os.path.exists(local_path) and os.path.getsize(local_path) > 0:\n",
    "        print(f\"LoRA downloaded successfully: {local_path}\")\n",
    "    else:\n",
    "        print(f\"âŒ LoRA download failed or file is empty: {local_path}\")\n",
    "    return filename\n",
    "\n",
    "def download_lora(link, folder=\"/content/ComfyUI/models/loras\", civitai_token=None):\n",
    "    if \"civitai.com\" in link.lower():\n",
    "        if not civitai_token:\n",
    "            raise ValueError(\"Civitai token is required for Civitai downloads\")\n",
    "        return download_civitai_model(link, civitai_token, folder)\n",
    "    else:\n",
    "        return download_with_aria2c(link, folder)\n",
    "\n",
    "def model_download(url: str, dest_dir: str, filename: str = None, silent: bool = True) -> str | bool:\n",
    "    try:\n",
    "        Path(dest_dir).mkdir(parents=True, exist_ok=True)\n",
    "        if filename is None:\n",
    "            filename = url.split('/')[-1].split('?')[0].replace('%20', ' ')\n",
    "        \n",
    "        full_path = Path(dest_dir) / filename\n",
    "        if full_path.exists():\n",
    "            if silent:\n",
    "                print(f\"Skipping {filename} (already exists)...\", end=' ', flush=True)\n",
    "            return filename\n",
    "\n",
    "        cmd = ['aria2c', '--console-log-level=error', '-c', '-x', '16', '-s', '16', '-k', '1M', '-d', dest_dir, '-o', filename, url]\n",
    "        if silent:\n",
    "            cmd.extend(['--summary-interval=0', '--quiet'])\n",
    "            print(f\"Downloading {filename}...\", end=' ', flush=True)\n",
    "        \n",
    "        subprocess.run(cmd, check=True, capture_output=silent, text=True)\n",
    "        \n",
    "        if silent:\n",
    "            print(\"Done!\")\n",
    "        else:\n",
    "            print(f\"Downloaded {filename} to {dest_dir}\")\n",
    "        return filename\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\nâŒ Error downloading {filename}: {e.stderr.strip() if e.stderr else 'Unknown error'}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ An unexpected error occurred: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def image_width_height(image):\n",
    "    if image.ndim == 4: _, height, width, _ = image.shape\n",
    "    elif image.ndim == 3: height, width, _ = image.shape\n",
    "    else: raise ValueError(f\"Unsupported image shape: {image.shape}\")\n",
    "    return width, height\n",
    "\n",
    "def clear_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache(); torch.cuda.ipc_collect()\n",
    "    gc.collect()\n",
    "\n",
    "def save_as_mp4(images, filename_prefix, fps, output_dir=\"/content/ComfyUI/output\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"{output_dir}/{filename_prefix}.mp4\"\n",
    "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
    "    with imageio.get_writer(output_path, fps=fps, codec='libx264', quality=8) as writer:\n",
    "        for frame in frames: writer.append_data(frame)\n",
    "    return output_path\n",
    "\n",
    "def save_as_image(image, filename_prefix, output_dir=\"/content/ComfyUI/output\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = f\"{output_dir}/{filename_prefix}.png\"\n",
    "    frame = (image.cpu().numpy() * 255).astype(np.uint8)\n",
    "    Image.fromarray(frame).save(output_path)\n",
    "    return output_path\n",
    "\n",
    "def save_as_webm(images, filename_prefix, fps, codec=\"vp9\", quality=32, output_dir=\"/content/ComfyUI/output\"):\n",
    "    os.makedirs(output_dir, exist_ok=True); output_path = f\"{output_dir}/{filename_prefix}.webm\"\n",
    "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
    "    kwargs = {'fps': int(fps), 'quality': int(quality), 'codec': str(codec), 'output_params': ['-crf', str(int(quality))]}\n",
    "    with imageio.get_writer(output_path, format='FFMPEG', mode='I', **kwargs) as writer:\n",
    "        for frame in frames: writer.append_data(frame)\n",
    "    return output_path\n",
    "\n",
    "def display_video(video_path):\n",
    "    from base64 import b64encode\n",
    "    video_data = open(video_path,'rb').read()\n",
    "    mime_type = f\"video/{video_path.split('.')[-1]}\"\n",
    "    data_url = f\"data:{mime_type};base64,\" + b64encode(video_data).decode()\n",
    "    display(HTML(f'<video width=512 controls autoplay loop><source src=\"{data_url}\" type=\"{mime_type}\"></video>'))\n",
    "\n",
    "def swapT(pa, f, s):\n",
    "    return s if pa == f else pa\n",
    "\n",
    "output_path = \"\"\n",
    "output_pathU = \"\"\n",
    "\n",
    "def generate_video(\n",
    "    image_path: str = None,\n",
    "    LoRA_Strength: float = 1.00,\n",
    "    rel_l1_thresh: float = 0.275,\n",
    "    start_percent: float = 0.1,\n",
    "    end_percent: float = 1.0,\n",
    "    positive_prompt: str = \"a cute anime girl\",\n",
    "    negative_prompt: str = \"...\",\n",
    "    width: int = 832,\n",
    "    height: int = 480,\n",
    "    seed: int = 0,\n",
    "    steps: int = 20,\n",
    "    cfg_scale: float = 1.0,\n",
    "    sampler_name: str = \"uni_pc\",\n",
    "    scheduler: str = \"simple\",\n",
    "    frames: int = 33,\n",
    "    fps: int = 16,\n",
    "    output_format: str = \"mp4\",\n",
    "    overwrite: bool = False,\n",
    "    use_lora: bool = True,\n",
    "    use_lora2: bool = True,\n",
    "    LoRA_Strength2: float = 1.00,\n",
    "    use_lora3: bool = True,\n",
    "    LoRA_Strength3: float = 1.00,\n",
    "    use_lightx2v: bool = False,\n",
    "    lightx2v_Strength: float = 0.80,\n",
    "    lightx2v_steps: int = 4,\n",
    "    use_pusa: bool = False, # 'false'ë¥¼ 'False'ë¡œ ìˆ˜ì •\n",
    "    pusa_Strength: float = 1.2,\n",
    "    pusa_steps: int = 6,\n",
    "    use_sage_attention: bool = True,\n",
    "    enable_flow_shift: bool = True,\n",
    "    shift: float = 8.0,\n",
    "    enable_flow_shift2: bool = True,\n",
    "    shift2: float = 8.0,\n",
    "    end_step1: int = 10,\n",
    "    prompt_assist: str = \"none\"\n",
    "):\n",
    "    # ì´ í•¨ìˆ˜ëŠ” ì—¬ê¸°ì„œ ì •ì˜ë˜ì§€ë§Œ ì‹¤ì œ í˜¸ì¶œì€ ë‚˜ì¤‘ ì…€ì—ì„œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\n",
    "    # ì´ ì…€ì—ì„œëŠ” ì„ ì–¸ë§Œ í•´ë‘ì–´ ë‚˜ì¤‘ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
    "    pass\n",
    "\n",
    "# --- END OF ALL HELPER FUNCTIONS ---\n",
    "\n",
    "# 6. UI ì„¤ì •ì— ë”°ë¼ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ\n",
    "try:\n",
    "    print(\"Downloading models based on UI settings...\")\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # LoRA ë‹¤ìš´ë¡œë“œ\n",
    "    lora_1, lora_2, lora_3 = None, None, None\n",
    "    if ui.download_lora_1.value and ui.lora_1_url.value:\n",
    "        lora_1 = download_lora(ui.lora_1_url.value, civitai_token=ui.civitai_token.value)\n",
    "    if ui.download_lora_2.value and ui.lora_2_url.value:\n",
    "        lora_2 = download_lora(ui.lora_2_url.value, civitai_token=ui.civitai_token.value)\n",
    "    if ui.download_lora_3.value and ui.lora_3_url.value:\n",
    "        lora_3 = download_lora(ui.lora_3_url.value, civitai_token=ui.civitai_token.value)\n",
    "\n",
    "    # lightx2v LoRA URL ê²°ì •\n",
    "    if ui.lightx2v_rank.value == \"32\":\n",
    "        lightx2v_url = \"https://huggingface.co/Isi99999/Wan2.1BasedModels/resolve/main/lightx2v_I2V_14B_480p_cfg_step_distill_rank32_bf16.safetensors\"\n",
    "    elif ui.lightx2v_rank.value == \"64\":\n",
    "        lightx2v_url = \"https://huggingface.co/Isi99999/Wan2.1BasedModels/resolve/main/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank64_bf16.safetensors\"\n",
    "    else: # 128\n",
    "        lightx2v_url = \"https://huggingface.co/Isi99999/Wan2.1BasedModels/resolve/main/lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank128_bf16.safetensors\"\n",
    "        \n",
    "    models_to_download = {\n",
    "        \"dit_model\": (f\"https://huggingface.co/Isi99999/Wan2.2BasedModels/resolve/main/wan2.2_i2v_high_noise_14B_{ui.model_quant.value}.gguf\", \"/content/ComfyUI/models/diffusion_models\"),\n",
    "        \"dit_model2\": (f\"https://huggingface.co/Isi99999/Wan2.2BasedModels/resolve/main/wan2.2_i2v_low_noise_14B_{ui.model_quant.value}.gguf\", \"/content/ComfyUI/models/diffusion_models\"),\n",
    "        \"text_encoder\": (\"https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors\", \"/content/ComfyUI/models/text_encoders\"),\n",
    "        \"main_vae\": (\"https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors\", \"/content/ComfyUI/models/vae\"),\n",
    "        \"clip_vision\": (\"https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors\", \"/content/ComfyUI/models/clip_vision\"),\n",
    "        \"lightx2v_lora\": (lightx2v_url, \"/content/ComfyUI/models/loras\"),\n",
    "        \"walkingToViewersL\": (\"https://huggingface.co/Isi99999/Wan2.1_14B-480p_I2V_LoRAs/resolve/main/walking%20to%20viewers_Wan.safetensors\", \"/content/ComfyUI/models/loras\"),\n",
    "        \"walkingFromBehindL\": (\"https://huggingface.co/Isi99999/Wan2.1_14B-480p_I2V_LoRAs/resolve/main/walking_from_behind.safetensors\", \"/content/ComfyUI/models/loras\"),\n",
    "        \"dancingL\": (\"https://huggingface.co/Isi99999/Wan2.1_14B-480p_I2V_LoRAs/resolve/main/b3ll13-d8nc3r.safetensors\", \"/content/ComfyUI/models/loras\"),\n",
    "        \"flux_model\": (\"https://huggingface.co/city96/FLUX.1-dev-gguf/resolve/main/flux1-dev-Q8_0.gguf\", \"/content/ComfyUI/models/unet\"),\n",
    "        \"flux_vae\": (\"https://huggingface.co/lovis93/testllm/resolve/ed9cf1af7465cebca4649157f118e331cf2a084f/ae.safetensors\", \"/content/ComfyUI/models/vae\"),\n",
    "        \"flux_clip_l\": (\"https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors\", \"/content/ComfyUI/models/clip\"),\n",
    "        \"flux_t5xxl\": (\"https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors\", \"/content/ComfyUI/models/clip\"),\n",
    "        \"upscaler_sharp\": (\"https://huggingface.co/lokCX/4x-Ultrasharp/resolve/main/4x-UltraSharp.pth\", \"/content/ComfyUI/models/upscale_models\"),\n",
    "        #\"upscaler_remacri\": (\"https://huggingface.co/Isi-dev/Upscalers/resolve/main/4x_foolhardy_Remacri.pth\", \"/content/ComfyUI/models/upscale_models\"),\n",
    "        #\"upscaler_anime\": (\"https://huggingface.co/Isi-dev/Upscalers/resolve/main/4x-AnimeSharp.pth\", \"/content/ComfyUI/models/upscale_models\"),\n",
    "    }\n",
    "    \n",
    "    download_results = {}\n",
    "    for name, (url, path) in models_to_download.items():\n",
    "        download_results[name] = model_download(url, path)\n",
    "\n",
    "    failed_models = [name for name, result in download_results.items() if not result]\n",
    "    if failed_models:\n",
    "        raise RuntimeError(f\"âŒ ë‹¤ìŒ í•„ìˆ˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {', '.join(failed_models)}. ì…€ 2ì˜ ì¶œë ¥ ë¡œê·¸ë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "    \n",
    "    for name, filename in download_results.items():\n",
    "        globals()[name] = filename\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(\"âœ… Environment Setup and Model Download Complete!\")\n",
    "    file_uploaded = None\n",
    "    upscaled_video_path = None\n",
    "\n",
    "except NameError:\n",
    "    print(\"UI object 'ui' is not defined. Skipping UI-based model downloads.\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3559ac9-a648-49da-8248-e507faa79f65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ì…€ 3: ì´ë¯¸ì§€ ì—…ë¡œë“œ (ë‘ ë²ˆì§¸ ì˜¤ë¥˜ ìˆ˜ì • ë²„ì „)\n",
    "import io\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# UI ìœ„ì ¯ì—ì„œ ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "uploaded_file_info = ui.image_uploader.value\n",
    "\n",
    "if not uploaded_file_info:\n",
    "    print(\"â€¼ï¸ ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš” (ì…€ 1ì˜ 'Upload Image' ë²„íŠ¼ ì‚¬ìš©).\")\n",
    "else:\n",
    "    # ë§ˆì§€ë§‰(ì²« ë²ˆì§¸)ìœ¼ë¡œ ì—…ë¡œë“œëœ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    last_uploaded_file = uploaded_file_info[0]\n",
    "    \n",
    "    filename = last_uploaded_file['name']\n",
    "    content = last_uploaded_file['content']\n",
    "    \n",
    "    # íŒŒì¼ ì €ì¥\n",
    "    save_dir = '/content/ComfyUI/input'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_uploaded = os.path.join(save_dir, filename)\n",
    "    \n",
    "    with open(file_uploaded, 'wb') as f:\n",
    "        f.write(content)\n",
    "        \n",
    "    print(f\"âœ… Image '{filename}' uploaded successfully to '{file_uploaded}'\")\n",
    "    \n",
    "    # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ í‘œì‹œ (ì˜µì…˜)\n",
    "    if ui.display_upload_check.value:\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):\n",
    "            img_data = io.BytesIO(content)\n",
    "            img = Image.open(img_data)\n",
    "            display(img)\n",
    "        else:\n",
    "            print(\"Cannot display this file type.\")\n",
    "    \n",
    "    # --- ìˆ˜ì •ëœ ë¶€ë¶„: ìœ„ì ¯ ê°’ì„ ìƒˆë¡œìš´ ë¹ˆ íŠœí”Œë¡œ ì„¤ì •í•˜ì—¬ ì´ˆê¸°í™” ---\n",
    "    ui.image_uploader.value = ()\n",
    "    \n",
    "    # ìœ„ì ¯ì˜ ë‚´ë¶€ ìƒíƒœë„ ì´ˆê¸°í™”í•˜ì—¬ ì¬ì—…ë¡œë“œê°€ ê°€ëŠ¥í•˜ê²Œ í•¨\n",
    "    ui.image_uploader._counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a23e23-d4c5-4776-a415-c82183bb3234",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ì…€ 4: ë¹„ë””ì˜¤ ìƒì„±\n",
    "import time\n",
    "import random\n",
    "\n",
    "if file_uploaded is None:\n",
    "    print(\"â€¼ï¸ ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì…€ 3ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "else:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # --- UI ê°’ ê°€ì ¸ì˜¤ê¸° ---\n",
    "    # ë¹„ë””ì˜¤ ì„¤ì •\n",
    "    positive_prompt_val = ui.positive_prompt.value\n",
    "    prompt_assist_val = ui.prompt_assist.value\n",
    "    prompt_assist_swap = swapT(prompt_assist_val, \"walking to camera\", \"walking to viewers\")\n",
    "    prompt_assist_swap = swapT(prompt_assist_swap, \"walking from camera\", \"walking from behind\")\n",
    "    prompt_assist_swap = swapT(prompt_assist_swap, \"swaying\", \"b3ll13-d8nc3r\")\n",
    "    final_positive_prompt = f\"{positive_prompt_val} {prompt_assist_swap}.\" if prompt_assist_swap != \"none\" else positive_prompt_val\n",
    "\n",
    "    # ì‹œë“œ ì„¤ì •\n",
    "    seed_val = ui.seed.value\n",
    "    if seed_val == 0:\n",
    "        seed_val = random.randint(0, 2**32 - 1)\n",
    "    print(f\"Using seed: {seed_val}\")\n",
    "    print(f\"prompt: {final_positive_prompt}\")\n",
    "    # ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ\n",
    "    generate_video(\n",
    "        image_path=file_uploaded,\n",
    "        LoRA_Strength=ui.lora_1_strength.value,\n",
    "        rel_l1_thresh=ui.rel_l1_thresh.value,\n",
    "        start_percent=ui.start_percent.value,\n",
    "        end_percent=ui.end_percent.value,\n",
    "        positive_prompt=final_positive_prompt,\n",
    "        prompt_assist=prompt_assist_swap,\n",
    "        negative_prompt=ui.negative_prompt.value,\n",
    "        width=ui.width.value,\n",
    "        height=ui.height.value,\n",
    "        seed=seed_val,\n",
    "        steps=ui.steps.value,\n",
    "        cfg_scale=ui.cfg_scale.value,\n",
    "        sampler_name=ui.sampler_name.value,\n",
    "        scheduler=ui.scheduler.value,\n",
    "        frames=ui.frames.value,\n",
    "        fps=16, # í•˜ë“œì½”ë”©ëœ ê°’\n",
    "        output_format=\"mp4\", # í•˜ë“œì½”ë”©ëœ ê°’\n",
    "        overwrite=ui.overwrite_previous_video.value,\n",
    "        use_lora=ui.use_lora_1.value,\n",
    "        use_lora2=ui.use_lora_2.value,\n",
    "        LoRA_Strength2=ui.lora_2_strength.value,\n",
    "        use_lora3=ui.use_lora_3.value,\n",
    "        LoRA_Strength3=ui.lora_3_strength.value,\n",
    "        use_lightx2v=ui.use_lightx2v.value,\n",
    "        lightx2v_Strength=ui.lightx2v_Strength.value,\n",
    "        lightx2v_steps=ui.steps.value, # steps ê°’ìœ¼ë¡œ ì„¤ì •\n",
    "        use_pusa=ui.use_lightx2v2.value,\n",
    "        pusa_Strength=ui.lightx2v2_Strength.value,\n",
    "        pusa_steps=ui.steps.value, # steps ê°’ìœ¼ë¡œ ì„¤ì •\n",
    "        use_sage_attention=ui.use_sage_attention.value,\n",
    "        enable_flow_shift=ui.use_flow_shift.value,\n",
    "        shift=ui.flow_shift.value,\n",
    "        enable_flow_shift2=ui.use_flow_shift.value,\n",
    "        shift2=ui.flow_shift2.value,\n",
    "        end_step1=ui.high_noise_steps.value\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    mins, secs = divmod(duration, 60)\n",
    "    print(f\"Seed: {seed_val}\")\n",
    "    print(f\"âœ… Generation completed in {int(mins)} min {secs:.2f} sec\")\n",
    "\n",
    "    clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b5144-1d2c-46cc-bb22-ed92d87399c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ì…€ 5: í”„ë ˆì„ ë³´ê°„ (Frame Interpolation)\n",
    "import glob\n",
    "import time\n",
    "\n",
    "if not ui.interpolate_video.value:\n",
    "    print(\"â˜‘ï¸ Frame interpolation skipped as per UI setting.\")\n",
    "elif not output_path or not os.path.exists(output_path):\n",
    "    print(\"â€¼ï¸ No video file found from the previous step. Cannot interpolate.\")\n",
    "else:\n",
    "    print(\"âœ¨ Applying Frame Interpolation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # UIì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°\n",
    "    frame_multiplier_val = ui.frame_multiplier.value\n",
    "    interpolated_fps_val = ui.interpolated_fps.value\n",
    "    crf_val = ui.crf_value.value\n",
    "\n",
    "    print(f\"Original video path: {output_path}\")\n",
    "    print(f\"Converting video. Multiplier: {frame_multiplier_val}x, Target FPS: {interpolated_fps_val}, CRF: {crf_val}\")\n",
    "\n",
    "    # os.chdir ëŒ€ì‹  %cd ë§¤ì§ ì»¤ë§¨ë“œ ì‚¬ìš©\n",
    "    %cd /content/Practical-RIFE\n",
    "    \n",
    "    # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (os.system ëŒ€ì‹  ! ì‚¬ìš©)\n",
    "    inference_command = f\"python3 inference_video.py --multi={frame_multiplier_val} --fps={interpolated_fps_val} --video='{output_path}' --scale=1\"\n",
    "    !{inference_command}\n",
    "\n",
    "    # ê²°ê³¼ íŒŒì¼ ì°¾ê¸° ë° ë³€í™˜\n",
    "    video_folder = \"/content/ComfyUI/output/\"\n",
    "    # RIFEëŠ” ì›ë³¸ íŒŒì¼ëª…ì— _[multiplier]x.mp4 ë¥¼ ì¶”ê°€í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    base_name = os.path.splitext(os.path.basename(output_path))[0]\n",
    "    interpolated_video_path = os.path.join(video_folder, f\"{base_name}_{frame_multiplier_val}X_30fps.mp4\")\n",
    "\n",
    "    if os.path.exists(interpolated_video_path):\n",
    "        final_output_path = \"/content/Practical-RIFE/output_converted.mp4\"\n",
    "        # ffmpeg ëª…ë ¹ì–´ ì‹¤í–‰ (os.system ëŒ€ì‹  ! ì‚¬ìš©)\n",
    "        ffmpeg_command = f\"ffmpeg -i '{interpolated_video_path}' -vcodec libx264 -crf {crf_val} -preset fast '{final_output_path}' -loglevel error -y\"\n",
    "        !{ffmpeg_command}\n",
    "        \n",
    "        print(f\"Displaying final video: {final_output_path}\")\n",
    "        display_video(final_output_path)\n",
    "    else:\n",
    "        print(f\"âŒ Interpolated video not found at expected path: {interpolated_video_path}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    mins, secs = divmod(duration, 60)\n",
    "    print(f\"âœ… Frame Interpolation completed in {int(mins)} min {secs:.2f} sec\")\n",
    "\n",
    "    clear_memory()\n",
    "    # ì‘ì—… í›„ ì›ë˜ ë””ë ‰í† ë¦¬ë¡œ ëŒì•„ê°\n",
    "    %cd /content/ComfyUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3051c1ca-08b8-4995-b0a6-ca10aa082599",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ì…€ 6: ë¹„ë””ì˜¤ ì—…ìŠ¤ì¼€ì¼ë§ (Flux Upscaler)\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "from custom_nodes.ComfyUI_UltimateSDUpscale.nodes import UltimateSDUpscale\n",
    "output_path = \"/content/ComfyUI/output/ComfyUI.mp4\"\n",
    "# --- ê²½ë¡œ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì½”ë“œ ì‹œì‘ ---\n",
    "# ComfyUI ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€í•˜ì—¬ ì»¤ìŠ¤í…€ ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
    "comfyui_path = '/content/ComfyUI'\n",
    "\n",
    "if comfyui_path not in sys.path:\n",
    "    sys.path.insert(0, comfyui_path)\n",
    "    print(f\"'{comfyui_path}' ê²½ë¡œë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ê²½ë¡œ ì¶”ê°€ í›„ ëª¨ë“ˆì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    from custom_nodes.ComfyUI_UltimateSDUpscale.nodes import UltimateSDUpscale\n",
    "except (ImportError, ModuleNotFoundError) as e:\n",
    "    print(\"âŒ ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: ì…€ 2(ì‚¬ì „ì„¤ì •)ê°€ ì˜¬ë°”ë¥´ê²Œ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    # git cloneìœ¼ë¡œ ìƒì„±ë˜ì–´ì•¼ í•  í´ë”ê°€ ìˆëŠ”ì§€ ì§ì ‘ í™•ì¸\n",
    "    expected_path = os.path.join(comfyui_path, 'custom_nodes', 'ComfyUI_UltimateSDUpscale')\n",
    "    if not os.path.exists(expected_path):\n",
    "        print(f\"ğŸ‘‰ í™•ì¸ ê²°ê³¼: '{expected_path}' ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì…€ 2ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ì»¤ìŠ¤í…€ ë…¸ë“œë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.\")\n",
    "    raise e # ì›ë˜ ì˜¤ë¥˜ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ ì…€ ì‹¤í–‰ì„ ì¤‘ì§€\n",
    "# --- ê²½ë¡œ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì½”ë“œ ë ---\n",
    "\n",
    "\n",
    "# ì—…ìŠ¤ì¼€ì¼ë§ì— í•„ìš”í•œ í—¬í¼ í•¨ìˆ˜\n",
    "def extract_frames(video_path):\n",
    "    \"\"\"ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ê³¼ FPSë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\"\"\"\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    frames = []\n",
    "    print(f\"Extracting frames from {os.path.basename(video_path)}...\")\n",
    "    while True:\n",
    "        success, frame = vidcap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "    print(f\"Extracted {len(frames)} frames at {fps:.2f} FPS\")\n",
    "    return frames, fps\n",
    "\n",
    "# --- ë©”ì¸ ì—…ìŠ¤ì¼€ì¼ë§ ë¡œì§ ---\n",
    "if not ui.apply_upscaling.value:\n",
    "    print(\"â˜‘ï¸ Video upscaling skipped as per UI setting.\")\n",
    "else:\n",
    "    # 5ë²ˆ ì…€(í”„ë ˆì„ ë³´ê°„)ì˜ ê²°ê³¼ë¬¼ ìš°ì„  íƒìƒ‰, ì—†ìœ¼ë©´ 4ë²ˆ ì…€(ë¹„ë””ì˜¤ ìƒì„±) ê²°ê³¼ë¬¼ ì‚¬ìš©\n",
    "    video_to_upscale = None\n",
    "    try:\n",
    "        # 'final_output_path'ëŠ” 5ë²ˆ ì…€ì˜ ê²°ê³¼ ë³€ìˆ˜ëª…, 'output_path'ëŠ” 4ë²ˆ ì…€ì˜ ê²°ê³¼ ë³€ìˆ˜ëª…ì…ë‹ˆë‹¤.\n",
    "        if 'final_output_path' in globals() and final_output_path and os.path.exists(final_output_path):\n",
    "            video_to_upscale = final_output_path\n",
    "            print(f\"Found interpolated video to upscale: {video_to_upscale}\")\n",
    "        elif 'output_path' in globals() and output_path and os.path.exists(output_path):\n",
    "            video_to_upscale = output_path\n",
    "            print(f\"Found generated video to upscale: {video_to_upscale}\")\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "    if not video_to_upscale:\n",
    "        print(\"â€¼ï¸ No video file found from previous steps. Cannot upscale.\")\n",
    "    else:\n",
    "        print(f\"âœ¨ Starting video upscale for: {os.path.basename(video_to_upscale)}\")\n",
    "        start_time = time.time()\n",
    "        clear_memory()\n",
    "\n",
    "        # ComfyUI ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "        clip_loader_upscale = DualCLIPLoader()\n",
    "        unet_loader_upscale = UnetLoaderGGUF()\n",
    "        vae_loader_upscale = VAELoader()\n",
    "        upscale_model_loader = UpscaleModelLoader()\n",
    "        positive_prompt_encode = CLIPTextEncodeFlux()\n",
    "        negative_prompt_encode = CLIPTextEncodeFlux()\n",
    "        upscaler_node = UltimateSDUpscale()\n",
    "        load_image_node = LoadImage()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            # ëª¨ë¸ ë¡œë”©\n",
    "            print(\"Loading FLUX models for upscaling...\")\n",
    "            clip = clip_loader_upscale.load_clip(flux_t5xxl, flux_clip_l, \"flux\")[0]\n",
    "            # ì—…ìŠ¤ì¼€ì¼ë§ ì‹œ í”„ë¡¬í”„íŠ¸ëŠ” ë¹„ì›Œë‘ì–´ ì›ë³¸ì„ ìµœëŒ€í•œ ìœ ì§€\n",
    "            positive = positive_prompt_encode.encode(clip, \"\", \"\", 3.5)[0]\n",
    "            negative = negative_prompt_encode.encode(clip, \"\", \"\", 3.5)[0]\n",
    "            del clip\n",
    "            \n",
    "            model = unet_loader_upscale.load_unet(flux_model)[0]\n",
    "            vae = vae_loader_upscale.load_vae(flux_vae)[0]\n",
    "            upscale_model = upscale_model_loader.load_model(ui.upscale_model_name.value)[0]\n",
    "\n",
    "            # í”„ë ˆì„ ì¶”ì¶œ\n",
    "            frames, fps = extract_frames(video_to_upscale)\n",
    "            upscaled_frames = []\n",
    "\n",
    "            # í”„ë ˆì„ë³„ ì—…ìŠ¤ì¼€ì¼ë§\n",
    "            for i, frame_array in enumerate(frames):\n",
    "                print(f\"Upscaling frame {i+1}/{len(frames)}...\")\n",
    "                # ë©”ëª¨ë¦¬ ë‚´ì—ì„œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ PIL Imageë¡œ ë³€í™˜ í›„ í…ì„œë¡œ ë³€í™˜\n",
    "                pil_image = Image.fromarray(frame_array)\n",
    "                image_tensor = torch.from_numpy(np.array(pil_image).astype(np.float32) / 255.0).unsqueeze(0)\n",
    "\n",
    "                # UltimateSDUpscale ë…¸ë“œ ì‹¤í–‰\n",
    "                upscaled_frame_tensor = upscaler_node.upscale(\n",
    "                    image=image_tensor, model=model, positive=positive, negative=negative, vae=vae,\n",
    "                    upscale_by=ui.upscale_by.value, seed=random.randint(0, 2**32 - 1), steps=ui.upscale_steps.value, cfg=1.0,\n",
    "                    sampler_name=\"dpmpp_2m\", scheduler=\"karras\", denoise=ui.upscale_denoise.value,\n",
    "                    upscale_model=upscale_model, mode_type=\"Linear\", tile_width=1024, tile_height=1024,\n",
    "                    mask_blur=8, tile_padding=32, seam_fix_mode=\"None\", seam_fix_denoise=1.0,\n",
    "                    seam_fix_width=64, seam_fix_mask_blur=8, seam_fix_padding=16, force_uniform_tiles=True,\n",
    "                    tiled_decode=False\n",
    "                )[0]\n",
    "                upscaled_frames.append(upscaled_frame_tensor)\n",
    "\n",
    "            # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "            del model, vae, upscale_model, positive, negative\n",
    "            clear_memory()\n",
    "\n",
    "            # ì—…ìŠ¤ì¼€ì¼ëœ ë¹„ë””ì˜¤ ì €ì¥ ë° í‘œì‹œ\n",
    "            if upscaled_frames:\n",
    "                print(\"Saving upscaled video...\")\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                upscaled_filename = f\"Upscaled_{timestamp}\"\n",
    "                upscaled_video_path = save_as_mp4(upscaled_frames, upscaled_filename, fps)\n",
    "                display_video(upscaled_video_path)\n",
    "\n",
    "                end_time = time.time()\n",
    "                duration = end_time - start_time\n",
    "                mins, secs = divmod(duration, 60)\n",
    "                print(f\"âœ… Upscaling completed in {int(mins)} min {secs:.2f} sec\")\n",
    "            else:\n",
    "                print(\"âŒ Upscaling failed, no frames were processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31c45b3-5894-4be2-b2ec-3304981b727b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ì…€ 7: íŒŒì¼ ì‚­ì œ\n",
    "!rm -R /content/ComfyUI/input/*\n",
    "!rm -R /content/ComfyUI/output/*\n",
    "print(\"ì‚­ì œì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b0ddb-cdf8-434a-9a9a-9b1192131297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
